---
title: Web Scrape Amazon with Beautiful Soup
author: Ashutosh Krishna
datePublished: 2022-10-19
description: Learn how to web scrape Amazon products using Beautiful Soup and Python in this project tutorial. 
header: https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/header.png
tags:
  - beginner
  - python
---

# Web Scrape Amazon with Beautiful Soup

<AuthorAvatar author_name="Ashutosh Krishna" author_avatar="/images/projects/authors/ashutosh_krishna.jpg" />

![Header image](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/header.png)

**Prerequisites:** Python fundamentals, HTML basics  
**Versions:** Python 3.10, requests 2.28.1, beautifulsoup4 4.11.1, lxml 4.9.1  
**Read Time:** 40 minutes  

## [#](#-introduction) Introduction

Have you ever missed an Amazon product that was available at a discounted price? Have you ever thought of building an application that notifies you when the price of an Amazon product decreases below a certain price? If yes, let's build it together.

In this project tutorial, we will build a Python program that "web scrapes" Amazon product details using [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).

The final result will look something like this:

![Demo](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/demo.gif)

## [#](#-what-is-web-scraping) What is Web Scraping?

The process of extracting data from a website is known as [web scraping](https://en.wikipedia.org/wiki/Web_scraping). This data is collected and then exported in a way that the user will find more valuable, such as an API or a CSV file. Manual web scraping is possible, but automated methods are typically preferred since they can be less expensive and faster.

While web scraping isn't illegal, it can become illegal if non-publicly available data is extracted. Web scraping can sometimes be difficult as the scraper may need to go through [CAPTCHAs](https://en.wikipedia.org/wiki/CAPTCHA) or the website changes frequently.

In Python, you can use the Beautiful Soup library to extract data out of HTML and XML files. With the help of parsers like **lxml**, you can navigate, search and modify the parse tree.  


## [#](#-setting-up) Setting up

First, open a Python code editor of your choice (VS Code recommended), and create a new Python file **scraper.py**. This is where we will be writing our code to scrape Amazon.

To start with, you will need to install three libraries: 
* The [`requests`](https://pypi.org/project/requests/) lets you send HTTP requests.
* The [`beautifulsoup4`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) lets you pull data out of HTML and XML files.
* The [`lxml`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser) provides powerful API for parsing HTML and XML.

To install the above-mentioned libraries, run the below command in your VS Code terminal:
```bash
pip install requests beautifulsoup4 lxml
```

## [#](#-scraping-amazon) Scraping Amazon

Before we get started, let's import the libraries we will be using in our Python file:

```python
import requests
from bs4 import BeautifulSoup
```

When we send an HTTP request, we send some **headers** along with the request. If you open devtools in your browsers(usually accessible through Command + Option + I or Control + Shift + I) and switch to the **Network** tab and reload any page, you can find the request headers that are similar to the ones shown below:

![Request Headers](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/request-headers.png)

Similar to browsers, we will also send some headers along with our HTTP request. Let's define them in a dictionary called `headers`:

```python
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.5"
}
```
To know your headers, you can also check out [this website](http://myhttpheader.com/).

Next, we will define a function `get_product_details()`. 

```python
def get_product_details(product_url: str) -> dict:
    pass
```
The function accepts a string parameter `product_url` and returns a dictionary. Let's call this dictionary `product_details`.

```python
def get_product_details(product_url: str) -> dict:

    # Create an empty product details dictionary
    product_details = {}
```

Now, let's make an HTTP request to get the HTML content of the product page. Using the `BeautifulSoup` class, we will create a [soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#making-the-soup) of the page content.
```python
def get_product_details(product_url: str) -> dict:

    # Create an empty product details dictionary
    product_details = {}
    
    # Get the product page content and create a soup
    page = requests.get(product_url, headers=headers)
    soup = BeautifulSoup(page.content, features="lxml")
``` 

Now comes the most important part of the tutorial where we will extract data from the page. For the sake of this tutorial, we will extract two data: 

- The **title** of the product.
- The **price** of the product.

But before extracting, let's learn how to view the HTML code that makes up any web page. Open a product page, say [this one](https://www.amazon.com/Acer-Chromebook-Graphics-802-11ac-CB512-C1KJ/dp/B09Q9YKW15) on your browser. 

![Amazon Product Page](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/amazon-product-page.png)

To view the HTML code, we have an **Inspect** option in every browser. You can use the keyboard shortcuts â€“ Ctrl + Shift + I for Windows or Linux and Cmd + Option + I for macOS users. Alternatively, right-click on the web page and choose **Inspect** to access the Developer tools panel. Make sure you are on the **Elements** tab in the Developer tools panel.

![Inspect Element](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/inspect-element.gif)

### Extracting the Title of the Product
 
Use the **Inspect** option to view the HTML code used for the title of the product.

![Extracting Title](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/extracting-title.png)

The title is wrapped with a `span` tag with an attribute id **productTitle**. Let's use this id to extract the title of the product.

```python
title = soup.find("span", attrs={"id": "productTitle"}).get_text().strip()
```
We use the `.find()` method to find a `span` element. Then pass the `productTitle` id in a dictionary called `attrs` that accepts the attributes. The `.get_text()` method returns the text in a string format. The `.strip()` method is used to remove any extra leading and trailing whitespaces.

### Extracting the Price of the Product

Similar to the title of the product, if you inspect the prices by right clicking on them and opening devtools, you will find the below HTML code for the price of the product.

![Extracting Price](https://raw.githubusercontent.com/codedex-io/projects/main/projects/web-scrape-amazon-with-beautiful-soup/extracting-price.png)

Thus, we can extract the price in a similar fashion.

```python
price = soup.find("span", attrs={"class": "apexPriceToPay"}).get_text().strip()
```

But, you will see a problem when you print the price of the product. The extracted price will be something like **$166.00$166.00** because the parent `span` element contains two `span` elements with the price text in them. But we can clean this extracted price to get the price of the product in the following way:

```python
extracted_price = soup.find("span", attrs={"class": "apexPriceToPay"}).get_text().strip()
price = "$" + extracted_price.split("$")[1]
```
First we split the `extracted_price` string using the `$` symbol using `extracted_price.split("$")`. This will return a list: `['', '166.00', '166.00']`. We then select the element at index 1 from the list. We also add the dollar sign before the price.

Now that you have extracted the product details, you can put them inside the `product_details` dictionary as below:

```python
# Adding it to the product details dictionary
product_details["title"] = title
product_details["price"] = price
```

So, the `get_product_details()` function will now look like:

```python
def get_product_details(product_url: str) -> dict:

    # Create an empty product details dictionary
    product_details = {}

    # Get the product page content and create a soup
    page = requests.get(product_url, headers=headers)
    soup = BeautifulSoup(page.content, features="lxml")
    try:
        # Scrape the product details
        title = soup.find("span", attrs={"id": "productTitle"}).get_text().strip()
        extracted_price = soup.find("span", attrs={"class": "apexPriceToPay"}).get_text().strip()
        price = extracted_price.split("$")[1]
        
        
        # Adding it to the product details dictionary
        product_details["title"] = title
        product_details["price"] = price
        product_details["product_url"] = product_url

        # Return the product details dictionary
        return product_details
    except Exception as e:
        print("Could not fetch product details")
        print(f"Failed with exception: {e}")
```

Notice that we have used **try-except** block to catch any error.

## [#](#-running-the-scraper) Running the Scraper

To run the scraper, we will ask the user to enter any product URL. Then we will call the `get_product_details()` function with that product URL and print it.

```python
product_url = input("Enter product url: ")
product_details = get_product_details(product_url)

print(product_details)

```

## [#](#-conclusion) Conclusion

In this tutorial, we scraped Amazon to extract the title and price of a product. You can follow the same pattern to extract more details like the rating of the product or its availability.

As mentioned before, the layout of Amazon will keep changing and hence, the above code may not be helpful in the future. Join CodÃ©dex Club to get support from code mentors if you run into any trouble while using this article!

## [#](#-more-resources) More Resources

- [Solution on GitHub](https://github.com/codedex-io/projects/blob/main/projects/web-scrape-amazon-with-beautiful-soup/scraper.py)
- [Documentation: requests](https://pypi.org/project/requests/)
- [Documentation: beautifulsoup4](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
